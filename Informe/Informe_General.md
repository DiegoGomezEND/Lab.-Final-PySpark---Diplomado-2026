# **An√°lisis de la Din√°mica Contractual del Estado Colombiano usando Datos Abiertos de SECOP II**

**Desarrollado por:** Diego Alejandro Gomez Cortes

### **Introducci√≥n**

SECOP II (Sistema Electr√≥nico para la Contrataci√≥n P√∫blica) es la principal plataforma de transparencia y seguimiento de la contrataci√≥n estatal en Colombia. A trav√©s de esta plataforma se registran los contratos p√∫blicos de entidades nacionales y territoriales, permitiendo el acceso abierto a informaci√≥n clave como valores contratados, tipos de contrato, entidades, proveedores y estados contractuales. El volumen, diversidad y naturaleza p√∫blica de estos datos convierten a SECOP II en una fuente estrat√©gica para el an√°lisis econ√≥mico, administrativo y de pol√≠tica p√∫blica.

El an√°lisis de los datos de SECOP II permite identificar patrones de contrataci√≥n, concentraci√≥n de recursos, comportamientos por territorio y modalidades contractuales, as√≠ como posibles riesgos o ineficiencias en el uso de los recursos p√∫blicos. Dado que la contrataci√≥n estatal representa una porci√≥n significativa del gasto p√∫blico, su estudio sistem√°tico aporta valor tanto para la toma de decisiones institucionales como para el control ciudadano y el desarrollo de modelos anal√≠ticos y predictivos.

Desde una perspectiva de datos, SECOP II plantea retos propios de los entornos Big Data: grandes vol√∫menes de informaci√≥n, esquemas complejos, datos heterog√©neos y actualizaciones constantes. Por esta raz√≥n, el uso de herramientas distribuidas como Apache Spark, Visual Studio Code, Java, JupyterLab y Docker resultan fundamentales para procesar, explorar y preparar estos datos de forma eficiente y escalable.

### **Objetivo del An√°lisis**

El objetivo de este trabajo es comprender el comportamiento de la contrataci√≥n p√∫blica registrada en SECOP II, explorando sus principales caracter√≠sticas estructurales y econ√≥micas mediante t√©cnicas de an√°lisis de datos a gran escala. A partir de esta exploraci√≥n, se busca sentar las bases para la construcci√≥n de an√°lisis avanzados y modelos de Machine Learning que permitan extraer conocimiento √∫til sobre la din√°mica contractual del Estado colombiano.

## **Cargue de los Datos**

En una primera fase, se tuvo en cuenta la construccion de entornos de trabajos adecuados para el tratamiento de los datos del Secop para asi mismos tratar con diferentes entornos que nos ayudaran asu analisis y gracias a esto se realiz√≥ la ingesta de datos directamente desde la API de Datos Abiertos Colombia, seleccionando los contratos m√°s recientes que cuentan con fecha de firma registrada. Posteriormente, la informaci√≥n fue cargada en un entorno distribuido con Apache Spark, donde se explor√≥ su esquema y se normalizaron los nombres de las columnas para garantizar consistencia t√©cnica.

Asi mismo se seleccionaron las variables clave relevantes para el an√°lisis y modelado, y el conjunto de datos resultante fue almacenado en formato Parquet optimizado. Este proceso permiti√≥ disponer de una base de datos estructurada, eficiente y lista para an√°lisis exploratorio y etapas posteriores de Machine Learning distribuido.

Query: **01_ingesta_resuelto.ipynb**

## **An√°lisis Exploratorio de Datos (EDA)**

En esta fase se realiz√≥ un an√°lisis exploratorio sobre los contratos electr√≥nicos del SECOP II con el objetivo de comprender la estructura del dataset, la distribuci√≥n de los valores contractuales y los patrones principales por territorio, tipo y estado del contrato. Este an√°lisis permite validar la calidad de los datos y preparar el terreno para la construcci√≥n de variables y modelos de Machine Learning distribuido.

Inicialmente se valid√≥ el **periodo temporal efectivo** de los datos analizados a partir de la columna `fecha_de_firma`. Los resultados muestran que los contratos incluidos corresponden principalmente al √∫ltimo trimestre de 2025 y los primeros registros de 2026, confirmando que el dataset representa contratos efectivamente firmados y no simples registros administrativos pendientes.

Posteriormente se calcularon **estad√≠sticas descriptivas generales** y espec√≠ficas para la variable objetivo `valor_del_contrato`. Se identific√≥ una distribuci√≥n altamente asim√©trica, donde la mayor√≠a de los contratos se concentran en rangos bajos y medios, mientras que una fracci√≥n menor representa contratos de muy alto valor. El an√°lisis por rangos permiti√≥ cuantificar esta concentraci√≥n y evidenciar la existencia de contratos de alto impacto presupuestal.

En el an√°lisis territorial se observ√≥ una fuerte concentraci√≥n de contratos en grandes centros administrativos como Bogot√°, Antioquia y Valle del Cauca, tanto en n√∫mero de contratos como en valor total adjudicado. Este comportamiento refleja la centralizaci√≥n de la contrataci√≥n p√∫blica y justifica el uso de an√°lisis regionales m√°s detallados en fases posteriores.

![Distribuci√≥n de contratos por departamento](../Imagenes/imagen1.png)

Tambien se explor√≥ la distribuci√≥n por **tipo de contrato**, donde la modalidad de **Prestaci√≥n de Servicios** domina ampliamente el volumen de contratos, seguida por modalidades administrativas espec√≠ficas y contratos de compra y suministro. En cuanto al **estado del contrato**, la mayor√≠a se encuentran en ejecuci√≥n o han sufrido modificaciones, lo cual es consistente con procesos contractuales activos y din√°micos.

Aparte se aplic√≥ el m√©todo **IQR (Interquartile Range)** para la detecci√≥n de outliers en el valor del contrato, excluyendo previamente valores iguales o menores a cero. El an√°lisis identific√≥ aproximadamente un 15% de contratos como valores at√≠picos superiores, los cuales no representan errores, sino contratos de gran escala con alto impacto presupuestal. Este resultado confirma la necesidad de aplicar transformaciones y t√©cnicas de escalamiento en las siguientes fases del pipeline de Machine Learning.

El estudio temporal por a√±o y mes evidenci√≥ picos claros de contrataci√≥n hacia finales de 2025, con una disminuci√≥n marcada al inicio de 2026, lo cual coincide con ciclos fiscales y administrativos propios de la contrataci√≥n p√∫blica en Colombia.

Query: **02_exploracion_eda_resuelto.ipynb**

## Feature Engineering y Construcci√≥n de Pipelines

En esta fase se prepararon los datos del **SECOP II** para su uso en modelos de *Machine Learning* utilizando **Spark ML**. A partir del dataset explorado en la fase de EDA, se transformaron variables categ√≥ricas y num√©ricas en un **vector de caracter√≠sticas num√©ricas (`features_raw`)**, requisito fundamental para entrenar algoritmos de aprendizaje autom√°tico. El proceso se aplic√≥ sobre **100.000 contratos**, garantizando consistencia, escalabilidad y reutilizaci√≥n mediante el uso de **Pipelines**.

### Selecci√≥n de variables

**Variables categ√≥ricas**

Se seleccionaron variables con alto poder explicativo y relevancia contractual:

- `departamento`
- `tipo_de_contrato`
- `estado_contrato`

Estas variables permiten capturar diferencias territoriales, administrativas y operativas entre los contratos registrados en SECOP II.

**Variable num√©rica**

- `valor_del_contrato_num`

Esta variable representa el valor monetario del contrato y es el principal insumo cuantitativo del modelo.

---

### Limpieza de datos

Se utiliz√≥ una estrategia de **eliminaci√≥n de valores nulos (`dropna`)** √∫nicamente sobre las variables seleccionadas para el modelo. Esta decisi√≥n se tom√≥ para evitar sesgos y mantener integridad en el proceso de entrenamiento.

- Registros antes de limpieza: **100.000**
- Registros despu√©s de limpieza: **100.000**

No se perdi√≥ informaci√≥n, lo que evidencia una **alta calidad del dataset** y permite avanzar sin necesidad de imputaciones artificiales.

---

### Codificaci√≥n de variables categ√≥ricas

Las variables categ√≥ricas fueron transformadas usando:

1. **StringIndexer**: conversi√≥n de texto a √≠ndices num√©ricos
2. **OneHotEncoder**: transformaci√≥n de √≠ndices a vectores binarios

**Categor√≠as detectadas**

| Variable            | Categor√≠as √∫nicas |
|---------------------|------------------|
| departamento         | 34               |
| tipo_de_contrato     | 20               |
| estado_contrato      | 7                |

**Resultado del OneHotEncoding**

- Total de features categ√≥ricas generadas: **61**
- Features num√©ricas originales: **1**

**Total de features esperadas:** **62**


### Construcci√≥n del vector de features

Las variables num√©ricas y las categ√≥ricas codificadas fueron combinadas mediante **VectorAssembler**, generando un √∫nico vector:

- `features_raw`

**Validaci√≥n del resultado**

- Dimensi√≥n esperada del vector: **62**
- Dimensi√≥n real del vector `features_raw`: **62**

Esto confirma que el proceso de codificaci√≥n y ensamblaje se ejecut√≥ correctamente.

---

### Construcci√≥n del Pipeline

El pipeline se construy√≥ respetando el orden l√≥gico de las transformaciones:

1. StringIndexer  
2. OneHotEncoder  
3. VectorAssembler  

**Resultado del pipeline**

- Total de stages: **7**
  - 3 StringIndexer
  - 3 OneHotEncoder
  - 1 VectorAssembler

El pipeline fue entrenado y aplicado exitosamente sobre el dataset limpio, garantizando reproducibilidad y consistencia en futuras ejecuciones.

### An√°lisis de varianza de features

Se realiz√≥ un an√°lisis de varianza sobre el vector `features_raw` para identificar las dimensiones con mayor capacidad de diferenciaci√≥n.

**Top 5 features con mayor varianza**

| Feature | Varianza |
|--------|----------|
| Feature 0  | 8.337e+18 |
| Feature 35 | 0.1948 |
| Feature 1  | 0.1699 |
| Feature 55 | 0.1618 |
| Feature 2  | 0.1275 |

**Interpretaci√≥n:**

- **Feature 0** corresponde al valor del contrato, lo que explica su alta varianza debido a la escala monetaria.
- Las dem√°s features representan categor√≠as espec√≠ficas con fuerte impacto en la diferenciaci√≥n de contratos.
- Este comportamiento justifica la necesidad de aplicar **normalizaci√≥n y reducci√≥n de dimensionalidad (PCA)** en la siguiente fase.


## Transformaciones Avanzadas 

En esta fase se aplicaron transformaciones avanzadas sobre el dataset previamente procesado mediante Feature Engineering, con el objetivo de **mejorar la calidad de las variables de entrada**, **reducir problemas derivados de escalas heterog√©neas** y **disminuir la dimensionalidad del espacio de features** antes de entrenar modelos de Machine Learning.

El punto de partida fue el dataset `secop_features.parquet`, el cual contiene un vector de caracter√≠sticas (`features_raw`) de 62 dimensiones, compuesto por variables num√©ricas y categ√≥ricas codificadas.

---

**¬øPor qu√© normalizar?**

Al inspeccionar los primeros registros del vector `features_raw`, se evidenci√≥ una **alta disparidad en las escalas de las variables**. Por ejemplo, el primer valor del vector corresponde al valor del contrato y presenta magnitudes del orden de millones, mientras que las variables categ√≥ricas codificadas toman valores binarios (0 o 1).

Ejemplo de valores observados en `features_raw`: [4.5588e+06, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]

Esta diferencia de escalas representa un problema para algoritmos de Machine Learning, ya que las variables con valores grandes dominan el proceso de aprendizaje, afectando negativamente la convergencia y la interpretaci√≥n del modelo.

**Comparaci√≥n antes y despu√©s de StandardScaler**

Para solucionar el problema de escalas, se aplic√≥ `StandardScaler` sobre el vector `features_raw`, generando un nuevo vector normalizado denominado `features_scaled`.

**Estad√≠sticas comparativas:**

**Antes (features_raw):**
- Min: 0.00  
- Max: 75,952,011,382.00  
- Media: 4,756,215.14  
- Desviaci√≥n est√°ndar: 368,580,743.71  

**Despu√©s (features_scaled):**
- Min: 0.00  
- Max: 69.01  
- Media: 0.18  
- Desviaci√≥n est√°ndar: 1.12  

Estos resultados confirman que el escalado fue exitoso, logrando que todas las variables queden en una escala comparable, condici√≥n fundamental para aplicar t√©cnicas como PCA y modelos basados en distancia.

**Configuraci√≥n de PCA y selecci√≥n del n√∫mero de componentes**

Una vez normalizadas las variables, se aplic√≥ **An√°lisis de Componentes Principales (PCA)** con el objetivo de reducir la dimensionalidad del vector de features.

- Dimensi√≥n original del vector: **62**
- N√∫mero de componentes seleccionados (k): **30**

El valor de *k* fue ajustado progresivamente para analizar la varianza explicada y encontrar un balance entre reducci√≥n dimensional y conservaci√≥n de informaci√≥n.

Ejemplo del vector transformado (`features_pca`): DenseVector([0.4892, -1.1825, 1.2005, 1.7628, 0.3237, -0.0634, ...])

**An√°lisis de varianza explicada**

El an√°lisis de varianza explic√≥ c√≥mo cada componente principal contribuye a la informaci√≥n total del dataset.

Resultados acumulados con **k = 30** componentes:

- Componente 10: 22.27% de varianza acumulada
- Componente 20: 39.22% de varianza acumulada
- Componente 30: **55.67% de varianza acumulada**

Este comportamiento evidencia que la varianza est√° distribuida de forma relativamente homog√©nea entre las componentes, lo cual es consistente con datasets que incluyen una alta proporci√≥n de variables categ√≥ricas codificadas.

Aunque no se alcanza el 80% de varianza explicada, el uso de 30 componentes permite una **reducci√≥n del 51.6% de la dimensionalidad**, manteniendo una cantidad significativa de informaci√≥n relevante.

**Pipeline completo de transformaciones**

Finalmente, se integraron todas las transformaciones en un **Pipeline completo**, garantizando reproducibilidad, trazabilidad y correcta aplicaci√≥n del flujo de datos.

Orden de las transformaciones:
1. StandardScaler  
2. PCA  

Este orden es cr√≠tico, ya que PCA requiere que las variables est√©n previamente normalizadas para evitar sesgos en la identificaci√≥n de componentes principales.

Como resultado, se gener√≥ un dataset final listo para modelado (`secop_ml_ready.parquet`), compuesto por:
- `features_pca`: vector reducido de caracter√≠sticas
- `label`: valor del contrato (`valor_del_contrato_num`)

Adicionalmente, el pipeline entrenado fue persistido para su reutilizaci√≥n en fases posteriores del proyecto, asegurando consistencia entre entrenamiento e inferencia.


## **Modelos de Regresi√≥n** 

## **Regresi√≥n Lineal**

Se construyo un modelo de **Regresi√≥n Lineal en Spark ML** con el objetivo de predecir el **valor del contrato** a partir de las *features* construidas en las fases anteriores (Feature Engineering + PCA). El dataset utilizado corresponde al archivo `secop_ml_ready.parquet`, el cual contiene las variables transformadas y listas para modelado.

**Estrategia de Train/Test Split**

Se defini√≥ una estrategia de partici√≥n **70% entrenamiento / 30% prueba**, utilizando una semilla fija para garantizar reproducibilidad.

**Resultados del split:**
- Train: **70,122 registros (70%)**
- Test: **29,878 registros (30%)**

Esta proporci√≥n es adecuada para datasets grandes (100,000 registros), permitiendo un entrenamiento robusto sin sacrificar capacidad de evaluaci√≥n.

**Configuraci√≥n del Modelo de Regresi√≥n Lineal**

Se configur√≥ un modelo base de `LinearRegression` sin regularizaci√≥n, con los siguientes par√°metros:

- `featuresCol`: `features`
- `labelCol`: `label`
- `maxIter`: 100
- `regParam`: 0.0
- `elasticNetParam`: 0.0

Este modelo sirve como **baseline**, permitiendo evaluar el comportamiento inicial antes de aplicar regularizaci√≥n en fases posteriores.

**Interpretaci√≥n del R¬≤ del Modelo (Train)**

El modelo fue entrenado sobre el conjunto de entrenamiento, obteniendo:

**M√©tricas en Train:**
- **R¬≤ (train): 0.5648**
- **RMSE (train): $3,074,544,375**
 
El valor de R¬≤ indica que el modelo explica aproximadamente **56.5% de la variabilidad** del valor de los contratos en el conjunto de entrenamiento. Dado el alto nivel de heterogeneidad y presencia de outliers en los valores contractuales, este resultado es razonable para un modelo lineal base.

**An√°lisis de Calidad de Predicciones y Errores**

Se analizaron las predicciones sobre el conjunto de prueba, calculando:

- Error absoluto
- Error porcentual
- Identificaci√≥n de las peores predicciones

**Hallazgos clave:**

1. Se observaron errores absolutos elevados en contratos de valores muy altos.
2. Los errores porcentuales superan el 100% en contratos peque√±os, lo cual evidencia:
  - Alta dispersi√≥n en los valores
  - Dificultad del modelo lineal para capturar extremos
3. No se detectaron errores sistem√°ticos por duplicaci√≥n o fallas de c√°lculo.

Estos resultados son coherentes con la naturaleza altamente asim√©trica del valor de los contratos.

**Comparaci√≥n Train vs Test (Overfitting)**

Se evalu√≥ el modelo sobre el conjunto de prueba:

**M√©tricas en Test:**
- RMSE: **$3,048,622,156**
- MAE: **$587,881,077**
- R¬≤ (test): **0.5742**

**Comparaci√≥n Train vs Test:**
- R¬≤ Train: **0.5648**
- R¬≤ Test: **0.5742**
- Diferencia absoluta: **0.0095**
 
No se evidencia **overfitting**, ya que el desempe√±o en test es incluso ligeramente superior al de train.  
El modelo generaliza correctamente dentro de las limitaciones propias de la regresi√≥n lineal.

**An√°lisis de Coeficientes del Modelo**

- Intercepto: **$289,073,028**
- N√∫mero de coeficientes: **30** (correspondientes a los componentes PCA)

El intercepto representa el valor base estimado cuando todas las *features* son cero. Los coeficientes reflejan la contribuci√≥n relativa de cada componente principal (PCA), no de variables originales, por lo que su interpretaci√≥n es **indirecta**.

**An√°lisis de Distribuci√≥n de Residuos**

Se calcul√≥ el residuo como:

\[
residuo = label - prediction
\]

Se gener√≥ un histograma para evaluar su distribuci√≥n.

**Resultado visual:**

![Distribuci√≥n de Residuos](../Imagenes/imagen2.png)

**Interpretaci√≥n:**
- Los residuos est√°n centrados alrededor de cero.
- Existe alta concentraci√≥n cerca del origen, con colas largas, lo cual es consistente con:
  - Presencia de outliers
  - Variabilidad extrema en los valores contractuales
- No se observa sesgo sistem√°tico severo.

**Feature Importance Aproximado (Componentes PCA)**

Se analizaron los coeficientes del modelo para identificar los componentes PCA m√°s influyentes (por valor absoluto):

**Top 10 componentes m√°s importantes:**
1. PC8      
2. PC9  
3. PC7  
4. PC3  
5. PC10  
6. PC1  
7. PC6  
8. PC4  
9. PC26  
10. PC16  

Estos componentes concentran mayor informaci√≥n relevante para la predicci√≥n. Al tratarse de PCA, no se interpretan directamente como variables originales, sino como combinaciones lineales de ellas, y el resultado confirma que solo una fracci√≥n de los componentes tiene impacto significativo.


## **Regresi√≥n Log√≠stica para Clasificaci√≥n de Riesgo Contractual**

En esta fase se construy√≥ un modelo de regresi√≥n log√≠stica con el objetivo de clasificar los contratos del SECOP II seg√∫n su nivel de riesgo, a partir de las variables transformadas en las etapas previas del pipeline. A diferencia de la regresi√≥n lineal, este modelo aborda un problema de clasificaci√≥n binaria, donde el inter√©s principal es estimar la probabilidad de que un contrato sea considerado de alto riesgo.

El dataset utilizado corresponde a `secop_features.parquet`, el cual contiene 100.000 contratos con variables categ√≥ricas codificadas y variables num√©ricas listas para modelado.

Query: **06_regresion_logistica.py**

**Creaci√≥n de la variable objetivo binaria**

Dado que el dataset original no cuenta con una variable expl√≠cita de riesgo, fue necesario construir una variable objetivo binaria denominada `riesgo`. Para ello se defini√≥ un criterio combinado que contempla tanto el riesgo financiero como el riesgo operativo por el tiempo.

Se establecieron las siguientes reglas:

- Riesgo financiero: contratos cuyo valor supera el percentil 90 del valor del contrato.
- Riesgo operativo: contratos con duraci√≥n definida menor a 30 d√≠as.

La regla financiera se aplic√≥ a todos los contratos, mientras que la regla operativa solo se utiliz√≥ cuando la duraci√≥n del contrato estaba disponible. Los contratos con duraci√≥n no definida fueron clasificados √∫nicamente con base en el criterio financiero, evitando su exclusi√≥n del an√°lisis.

Como resultado, se obtuvo la siguiente distribuci√≥n:

- Contratos de alto riesgo (1): **30.717**
- Contratos de bajo riesgo (0): **69.283**
- Total de registros: **100.000**

Este procedimiento permiti√≥ construir una variable objetivo consistente, sin p√©rdida de informaci√≥n y alineada con criterios reales de riesgo contractual.

**An√°lisis del balance de clases**

Se analiz√≥ la distribuci√≥n de la variable `riesgo` para evaluar el balance de clases. Los resultados muestran que aproximadamente el 30% de los contratos corresponden a la clase positiva (alto riesgo) y el 70% a la clase negativa (bajo riesgo).

Aunque el dataset no est√° perfectamente balanceado, el desbalance no es extremo, lo que permite entrenar un modelo base sin necesidad inmediata de t√©cnicas de remuestreo. No obstante, este escenario justifica el uso de m√©tricas adicionales a la accuracy y el posterior ajuste del threshold de clasificaci√≥n.

**Diferencia entre regresi√≥n log√≠stica y regresi√≥n lineal**

La regresi√≥n log√≠stica se diferencia de la regresi√≥n lineal en que no predice valores continuos, sino probabilidades asociadas a una clase. Utiliza una funci√≥n sigmoide para transformar la combinaci√≥n lineal de las variables de entrada en un valor entre 0 y 1, el cual se interpreta como la probabilidad de pertenecer a la clase positiva.

En este proyecto, la regresi√≥n lineal se utiliz√≥ para predecir el valor del contrato, mientras que la regresi√≥n log√≠stica se emple√≥ para clasificar contratos seg√∫n su nivel de riesgo, evidenciando la aplicabilidad de cada modelo seg√∫n la naturaleza del problema.

**Configuraci√≥n del modelo**

El modelo de regresi√≥n log√≠stica se configur√≥ con los siguientes par√°metros:

- `maxIter = 100`
- `regParam = 0.0`
- `threshold = 0.5`

Esta configuraci√≥n corresponde a un modelo base sin regularizaci√≥n, utilizado como punto de referencia antes de introducir penalizaciones y ajustes m√°s avanzados. El threshold de 0.5 se utiliz√≥ inicialmente como valor est√°ndar, siendo posteriormente analizado y ajustado en los retos bonus.

**Interpretaci√≥n de probabilidades**

La columna `probability` generada por el modelo representa la probabilidad estimada de pertenecer a cada clase, donde el segundo valor corresponde a la probabilidad de alto riesgo. Por ejemplo, un valor `probability = [0.8, 0.2]` indica una probabilidad del 20% de que el contrato sea de alto riesgo, por lo que, con un threshold de 0.5, ser√≠a clasificado como bajo riesgo.

El an√°lisis de las predicciones evidenci√≥ la existencia de casos cercanos al threshold, los cuales representan situaciones de mayor incertidumbre y refuerzan la importancia de evaluar m√©tricas adicionales y ajustar el criterio de decisi√≥n.

**Evaluaci√≥n del modelo con m√∫ltiples m√©tricas**

Para evaluar el desempe√±o del modelo se utilizaron m√©tricas apropiadas para clasificaci√≥n binaria:

- **AUC-ROC:** **0.8137**
- **Accuracy:** **0.8183**
- **Precision:** **0.8222**
- **Recall:** **0.8183**
- **F1-Score:** **0.8031**

El valor de AUC-ROC indica una buena capacidad del modelo para discriminar entre contratos de alto y bajo riesgo, independientemente del threshold utilizado. Las m√©tricas de precision y recall muestran un desempe√±o balanceado, lo que sugiere que el modelo logra identificar contratos riesgosos sin generar un n√∫mero excesivo de falsas alarmas.

**Matriz de confusi√≥n**

Se construy√≥ la matriz de confusi√≥n sobre el conjunto de prueba, obteniendo los siguientes resultados:

- True Positives (TP): **4.696**
- True Negatives (TN): **19.713**
- False Positives (FP): **867**
- False Negatives (FN): **4.554**

El an√°lisis muestra que el error m√°s cr√≠tico corresponde a los falsos negativos, ya que implican contratos de alto riesgo clasificados como bajo riesgo. En el contexto de la contrataci√≥n p√∫blica, este tipo de error es m√°s costoso que un falso positivo, lo cual justifica priorizar m√©tricas como el recall y el ajuste del threshold.

**Ajuste del threshold de clasificaci√≥n**

Se evalu√≥ el desempe√±o del modelo utilizando diferentes valores de threshold. Al aumentar el threshold a 0.7, se obtuvo:

- Accuracy: **0.806**
- Recall: **0.806**

Este resultado confirma el trade-off entre precisi√≥n y sensibilidad. Un threshold m√°s alto hace al modelo m√°s conservador, reduciendo la detecci√≥n de contratos riesgosos. Dado el objetivo del an√°lisis, se concluye que no es conveniente utilizar un threshold elevado y que valores cercanos o inferiores a 0.5 son m√°s adecuados para priorizar la detecci√≥n de riesgo.

**Curva ROC**

Se construy√≥ la curva ROC para visualizar el trade-off entre la tasa de verdaderos positivos (TPR) y la tasa de falsos positivos (FPR) a lo largo de distintos thresholds. La curva se encuentra claramente por encima de la l√≠nea de clasificaci√≥n aleatoria, confirmando la capacidad discriminatoria del modelo.

![Curva ROC - Regresi√≥n Log√≠stica](../Imagenes/imagen3.png)

El valor de AUC cercano a 0.81 respalda los resultados obtenidos en la evaluaci√≥n cuantitativa y valida el uso de la regresi√≥n log√≠stica como modelo base para la clasificaci√≥n de riesgo contractual.

## **Regularizaci√≥n L1, L2 y ElasticNet**

En esta fase se evalu√≥ el impacto de la regularizaci√≥n sobre el modelo de regresi√≥n lineal construido previamente con componentes principales (PCA). El objetivo fue analizar si la penalizaci√≥n L1, L2 o ElasticNet permit√≠a reducir el overfitting observado y mejorar la capacidad de generalizaci√≥n del modelo.

Dataset utilizado: `secop_ml_ready.parquet`  
Split aplicado: 70% entrenamiento ‚Äì 30% prueba  
Semilla: 42  

**Comprender la Regularizaci√≥n**

Escenario conceptual:

- R¬≤ train = 0.95  
- R¬≤ test = 0.45  

Este escenario indica **overfitting**. El modelo aprende demasiado bien los datos de entrenamiento pero no generaliza correctamente a datos nuevos.

La regularizaci√≥n introduce una penalizaci√≥n sobre los coeficientes del modelo, reduciendo su magnitud y limitando la complejidad. Esto ayuda a evitar que el modelo memorice ruido.

**Configuraci√≥n del Evaluador**

Se configur√≥ un evaluador basado en RMSE:

- Penaliza fuertemente errores grandes.
- Mantiene interpretabilidad en unidades monetarias.
- Es consistente con el an√°lisis previo realizado en regresi√≥n lineal.

M√©trica utilizada: `rmse`  

**Experimento con M√∫ltiples Regularizaciones**

Se entrenaron 18 modelos variando:

**regParam (Œª):**

- 0.0  
- 1.0  
- 10.0  
- 100.0  
- 1000.0  
- 10000.0  

**elasticNetParam (Œ±):**

- 0.0 ‚Üí Ridge  
- 0.5 ‚Üí ElasticNet  
- 1.0 ‚Üí Lasso  

Total modelos entrenados: 18  

**Resultados del Experimento**

**Modelo sin regularizaci√≥n:**

- RMSE Train: $2,797,195,710.17  
- RMSE Test:  $3,745,098,056.02  

**Ridge (Œª = 1):**

- RMSE Test: $3,745,098,056.37  

**ElasticNet (Œª = 1):**

- RMSE Test: $3,745,098,056.93  

**Lasso (Œª = 1):**

- RMSE Test: $3,745,098,057.49  

A medida que Œª aumenta, el RMSE Test aumenta ligeramente, indicando p√©rdida progresiva de capacidad predictiva (underfitting). El menor RMSE se obtuvo con Œª = 0.0. La regularizaci√≥n no mejor√≥ el desempe√±o del modelo en este caso.

**Comparaci√≥n de Overfitting**

Brecha aproximada:

Gap = RMSE_Test ‚àí RMSE_Train
Gap ‚âà 947,902,345.85

La brecha se mantiene pr√°cticamente constante en todas las configuraciones.

Interpretaci√≥n:

- No se observa reducci√≥n significativa del overfitting mediante regularizaci√≥n.
- El modelo basado en PCA ya presenta estabilidad estructural.
- Incrementar Œª solo aumenta el error sin reducir la brecha train-test.

**Modelo Final**

Se seleccion√≥ como mejor modelo:

- regParam = 0.0  
- elasticNetParam = 0.0  

Resultados finales:

- RMSE Train: $2,797,195,710.17  
- RMSE Test:  $3,745,098,056.02  

Modelo guardado en: /opt/spark-data/raw/regularized_model

**Efecto de Œª en Lasso**

Se evalu√≥ c√≥mo cambia el n√∫mero de coeficientes en cero al aumentar Œª en Lasso (L1).

Resultados:

- Œª = 0.01 ‚Üí 0/30 coeficientes en 0  
- Œª = 0.10 ‚Üí 0/30 coeficientes en 0  
- Œª = 1.00 ‚Üí 0/30 coeficientes en 0  
- Œª = 10.00 ‚Üí 0/30 coeficientes en 0  
- Œª = 100.00 ‚Üí 0/30 coeficientes en 0  
- Œª = 1000.00 ‚Üí 0/30 coeficientes en 0  

No se elimin√≥ ning√∫n coeficiente. Esto ocurre porque el modelo trabaja sobre componentes PCA, que son combinaciones lineales densas y ortogonales. Lasso tiende a generar sparsity cuando existen features originales altamente redundantes o poco relevantes, lo cual no sucede en este espacio reducido de 30 componentes principales.

#### Visualizaci√≥n del efecto de Œª

Efecto de Œª en la sparsity (Lasso):

![Efecto de Œª en la Sparsity](../Imagenes/imagen4.png)


Efecto de Œª en el error del modelo:

![Efecto de Œª en el Error](../Imagenes/imagen5.png)


Las gr√°ficas muestran que:

- El n√∫mero de coeficientes en cero permanece constante.
- El RMSE aumenta progresivamente al incrementar Œª.
- Valores altos de Œª inducen underfitting.

La regularizaci√≥n no mejor√≥ el desempe√±o del modelo en este dataset. Dado el uso previo de PCA en el cual se estabiliza el modelo reduciendo colinealidad. Asi mismo Lasso no gener√≥ sparsity debido a la naturaleza de los componentes principales. Por lo cual, valores altos de Œª aumentarian el error de predicci√≥n y en este caso espec√≠fico, el modelo sin regularizaci√≥n result√≥ √≥ptimo.

## **Optimizacion de Hiperparametros**

### **Validacion Cruzada**

La **Validaci√≥n Cruzada (K-Fold Cross-Validation)** con el objetivo de obtener una estimaci√≥n m√°s robusta del desempe√±o del modelo de regresi√≥n. A diferencia del simple train/test split, la validaci√≥n cruzada divide el conjunto de entrenamiento en *K subconjuntos*, entrenando el modelo m√∫ltiples veces y rotando el conjunto de validaci√≥n en cada iteraci√≥n. Esto permite reducir la varianza de la m√©trica y minimizar el riesgo de seleccionar un modelo que funcione bien solo por una partici√≥n favorable de los datos.

Se construy√≥ un **ParamGrid** que incluy√≥ m√∫ltiples combinaciones de hiperpar√°metros (`regParam`, `elasticNetParam`, `maxIter`, `fitIntercept`), generando un total de **36 combinaciones**. Con un valor de **K=5 folds**, el sistema entren√≥ **180 modelos en total**, evaluando cada uno mediante la m√©trica **RMSE**. El mejor modelo encontrado present√≥ los hiperpar√°metros `regParam = 1.0` y `elasticNetParam = 0.5` (ElasticNet), con un **RMSE promedio en Cross-Validation de 3,333,757,188.27**.

Posteriormente, el mejor modelo fue evaluado sobre el conjunto de prueba independiente, obteniendo un **RMSE en test de $2,342,402,953.62**, lo cual confirma un buen nivel de generalizaci√≥n. Se realiz√≥ adem√°s una comparaci√≥n entre el modelo obtenido mediante Cross-Validation y uno entrenado √∫nicamente con simple split, observ√°ndose resultados id√©nticos en este caso espec√≠fico, debido a la estabilidad del dataset y a la consistencia de los hiperpar√°metros seleccionados.

Por otro lado se realizo un experimento adicional variando el n√∫mero de folds (K=3, K=5 y K=10), observando que un mayor n√∫mero de folds reduce ligeramente el RMSE promedio pero incrementa considerablemente el tiempo computacional (23.5s, 36.1s y 71.1s respectivamente). Esto evidencia el trade-off cl√°sico entre robustez estad√≠stica y costo computacional. El modelo √≥ptimo fue guardado para su uso en fases posteriores de optimizaci√≥n avanzada y despliegue.

## **Optimizacion de Hiperparametros**

Se implementaron estrategias de optimizaci√≥n de hiperpar√°metros sobre el modelo de Regresi√≥n Lineal con regularizaci√≥n, utilizando los datos transformados del archivo `secop_ml_ready.parquet`. Se dise√±√≥ un grid de b√∫squeda en escala logar√≠tmica para `regParam` (0.01, 0.1, 1.0), distintos valores de `elasticNetParam` (0.0, 0.5, 1.0) y variaciones en `maxIter`. Este enfoque permiti√≥ evaluar combinaciones de Ridge (L2), Lasso (L1) y ElasticNet dentro de un marco estructurado y reproducible.

Se ejecut√≥ Grid Search combinado con Cross-Validation (K=3), obteniendo como mejor configuraci√≥n: `regParam = 1.0`, `elasticNetParam = 1.0` y `maxIter = 50`, con un RMSE en test de **$2,342,402,953.27**. El tiempo de ejecuci√≥n fue de 18.63 segundos. En paralelo, se implement√≥ Train-Validation Split con `trainRatio = 0.8`, logrando exactamente los mismos hiperpar√°metros √≥ptimos y el mismo RMSE en test, con un tiempo de ejecuci√≥n menor (6.66 segundos). Esto evidencia que, para este dataset, ambas estrategias convergieron al mismo m√≠nimo.

Se realiz√≥ un refinamiento adicional del grid alrededor de la mejor zona encontrada, probando valores cercanos como `regParam = 0.9` y `elasticNetParam = 0.9`. El nuevo modelo obtuvo un RMSE de **$2,342,402,953.42**, pr√°cticamente igual al anterior, lo que confirma que la regi√≥n √≥ptima es estable y que no existen mejoras significativas en esa vecindad del espacio de b√∫squeda.

El modelo √≥ptimo fue guardado en `/opt/spark-data/raw/tuned_model`, junto con los hiperpar√°metros seleccionados en un archivo JSON para garantizar trazabilidad. Los resultados muestran que el uso de regularizaci√≥n adecuada y validaci√≥n estructurada permite obtener un modelo robusto, con mejor capacidad de generalizaci√≥n frente a los experimentos iniciales sin ajuste sistem√°tico de hiperpar√°metros.

# **MLOps y Produccion**

## **MLflow Tracking**

En este reto se configur√≥ la conexi√≥n con el servidor de MLflow utilizando la URI `http://mlflow:5000`, lo que permiti√≥ centralizar el registro de experimentos en un servidor dedicado y no en archivos locales. Se cre√≥ el experimento `secop_prediccion`, donde se almacenan todos los runs relacionados con el modelo de predicci√≥n de contratos. Esto garantiza trazabilidad, organizaci√≥n y comparabilidad entre diferentes entrenamientos del modelo.

**Registro del Modelo Baseline**

Se entren√≥ un modelo base de regresi√≥n lineal sin regularizaci√≥n (`regParam=0.0`, `elasticNetParam=0.0`) utilizando como variable objetivo el **logaritmo del valor del contrato**, con el fin de estabilizar la varianza y reducir el impacto de valores extremos.

Las m√©tricas obtenidas fueron:

- **RMSE:** 1.45  
- **MAE:** 0.99  
- **R¬≤:** 0.3545  

Estas m√©tricas est√°n calculadas en **escala logar√≠tmica**, lo que implica que los errores representan diferencias relativas y no absolutas en pesos colombianos. El modelo fue almacenado como artefacto dentro del run, permitiendo su posterior consulta o descarga desde la interfaz de MLflow.

**Registro de M√∫ltiples Modelos (Ridge, Lasso y ElasticNet)**

Se entrenaron tres modelos adicionales con diferentes tipos de regularizaci√≥n: Ridge (L2), Lasso (L1) y ElasticNet (L1 + L2), todos con `regParam=0.1`. Cada run registr√≥ par√°metros, m√©tricas (RMSE, MAE y R¬≤) y el modelo entrenado como artefacto.

üîπ **Ridge**
- **RMSE:** 1.45  
- **MAE:** 1.00  
- **R¬≤:** 0.3530  

üîπ**Lasso**
- **RMSE:** 1.49  
- **MAE:** 1.04  
- **R¬≤:** 0.3192  

 üîπ **ElasticNet**
- **RMSE:** 1.46  
- **MAE:** 1.02  
- **R¬≤:** 0.3381  

Se observ√≥ que el modelo Ridge obtuvo el mejor desempe√±o general en t√©rminos de RMSE y R¬≤, aunque las diferencias entre modelos fueron moderadas.


**Exploraci√≥n y Comparaci√≥n en MLflow UI**

Se utiliz√≥ la interfaz web de MLflow para comparar los runs lado a lado, ordenar por RMSE y analizar las diferencias en par√°metros y m√©tricas. Se observ√≥ que el modelo Ridge present√≥ el menor RMSE (‚âà 1.45), consolid√°ndose como la mejor alternativa dentro de los experimentos evaluados.

![Comparaci√≥n de Modelos](../Imagenes/mlflow2.png)


## **Registro de Artefactos Personalizados**

Se cre√≥ un nuevo run donde, adem√°s de registrar el modelo y m√©tricas, se agreg√≥ un reporte en texto con los resultados y un gr√°fico de **predicciones vs valores reales en escala logar√≠tmica**. Este gr√°fico permiti√≥ visualizar el comportamiento del modelo respecto a la l√≠nea de predicci√≥n perfecta y evidenciar la tendencia del modelo a concentrarse alrededor de la media.

Estos archivos fueron almacenados como artefactos dentro de MLflow, permitiendo su visualizaci√≥n directa desde la interfaz.

![Predicciones vs Valores Reales](../Imagenes/mlflow3.png)


## **Model Registry**

El ciclo completo de gesti√≥n de modelos utilizando el **Model Registry de MLflow**, con el objetivo de versionar, promover y consumir modelos de forma controlada. Se logro, configurando la conexi√≥n al servidor de MLflow y se defini√≥ el nombre del modelo como `secop_prediccion_contratos` y se estableci√≥ el entorno para registrar versiones oficiales del modelo de predicci√≥n del valor de contratos SECOP.

En el primer paso se entren√≥ y registr√≥ la versi√≥n 1 (baseline) sin regularizaci√≥n, almacenando m√©tricas y registr√°ndola directamente en el Registry. Luego se entren√≥ la versi√≥n 2 con regularizaci√≥n (ElasticNet), comparando su RMSE frente al baseline. Tras la evaluaci√≥n, se determin√≥ que la versi√≥n 1 present√≥ un mejor desempe√±o, por lo que fue promovida a **Production**, mientras que la versi√≥n 2 fue archivada. Este proceso permiti√≥ aplicar correctamente el ciclo de vida: `None ‚Üí Staging ‚Üí Production ‚Üí Archived`.  
 
![Model_Registry](../Imagenes/mlflow4.png)

Posteriormente se agreg√≥ metadata y descripci√≥n formal al modelo en producci√≥n, incluyendo versi√≥n, RMSE validado, dataset utilizado, tipo de features (PCA), autor y fecha. Esto garantiza trazabilidad, documentaci√≥n t√©cnica y gobernanza del modelo dentro del Registry.  
 
![Model_Registry](../Imagenes/mlflow5.png)

Finalmente, se carg√≥ el modelo directamente desde el Registry utilizando la URI l√≥gica: "models:/secop_prediccion_contratos/Production", se verific√≥ su correcto funcionamiento realizando predicciones sobre el conjunto de prueba. El RMSE obtenido coincidi√≥ exactamente con el registrado durante el entrenamiento, confirmando reproducibilidad, control de versiones y correcta gesti√≥n del ciclo de vida del modelo.









