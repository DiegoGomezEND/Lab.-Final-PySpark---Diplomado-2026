{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a29532ae-ebb5-46af-aa32-67c74ee5d936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/02/14 06:46:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import col, log\n",
    "\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "\n",
    "# %%\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SECOP_MLflow\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9463aa1-8ae7-47c9-9782-5d57bbe68472",
   "metadata": {},
   "source": [
    "### **Configurar MLflow tracking server y experimento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "884ef18b-b73f-47ae-9fa0-f7518f6a6cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca52447b-8ba2-4110-85fc-b3feb81b5439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/14 06:46:43 INFO mlflow.tracking.fluent: Experiment with name 'secop_prediccion' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///opt/mlflow/mlruns/968059932841652694', creation_time=1771051603678, experiment_id='968059932841652694', last_update_time=1771051603678, lifecycle_stage='active', name='secop_prediccion', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name=\"secop_prediccion\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "726daa14-ae7b-4537-a8a4-ea8c445a712b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 80,153\n",
      "Test: 19,847\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"/opt/spark-data/raw/secop_ml_ready.parquet\")\n",
    "df = df.withColumnRenamed(\"valor_del_contrato_log\", \"label\") \\\n",
    "       .withColumnRenamed(\"features_pca\", \"features\") \\\n",
    "       .filter(col(\"label\").isNotNull())\n",
    "\n",
    "train, test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "print(f\"Train: {train.count():,}\")\n",
    "print(f\"Test: {test.count():,}\")\n",
    "\n",
    "# %%\n",
    "evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "evaluator_mae = RegressionEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"mae\"\n",
    ")\n",
    "evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08a20e4-6ab3-447d-a422-de7f0f23f71b",
   "metadata": {},
   "source": [
    "### **Registrar experimento baseline con log_param/log_metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "305a3b91-9ae5-48b0-b08d-c9b927a69c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/14 06:46:57 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experimento 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/14 06:46:58 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "26/02/14 06:46:59 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "26/02/14 06:46:59 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "26/02/14 06:47:00 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "/usr/local/lib/python3.11/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RMSE: $0.89\n",
      "✓ MAE: $0.46\n",
      "✓ R²: 0.7385\n"
     ]
    }
   ],
   "source": [
    "print(\"Experimento 1\")\n",
    "with mlflow.start_run(run_name=\"baseline_model\"):\n",
    "    # definamos parametros\n",
    "    reg_param = 0.1\n",
    "    elastic_param = 0.0\n",
    "    max_iter = 100\n",
    "\n",
    "    # Log de Parámetros\n",
    "    mlflow.log_param(\"regParam\", reg_param)\n",
    "    mlflow.log_param(\"elasticParam\", elastic_param)\n",
    "    mlflow.log_param(\"maxIaram\", max_iter)\n",
    "\n",
    "    # Entrenar Modelo\n",
    "    lr= LinearRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        regParam=reg_param,\n",
    "        elasticNetParam=elastic_param,\n",
    "        maxIter=max_iter\n",
    "    )\n",
    "\n",
    "    model = lr.fit(train)\n",
    "\n",
    "    # Generar Predicciones\n",
    "    predictions = model.transform(test)\n",
    "    \n",
    "    # Evaluar modelo\n",
    "    rmse = evaluator_rmse.evaluate(predictions)\n",
    "    mae = evaluator_mae.evaluate(predictions)\n",
    "    r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "    # Log de metricas\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # Guardar modelo\n",
    "    mlflow.spark.log_model(model, \"model\")\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"✓ RMSE: ${rmse:,.2f}\")\n",
    "    print(f\"✓ MAE: ${mae:,.2f}\")\n",
    "    print(f\"✓ R²: {r2:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c94f9-a0c5-4b39-b697-fd644a2a4c30",
   "metadata": {},
   "source": [
    "### **Registrar multiples modelos (Ridge, Lasso, ElasticNet)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34123ca6-0f4d-4c17-9e7d-2e8a0ec9ae35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGISTRANDO MODELOS CON DIFERENTE REGULARIZACIÓN\n",
      "\n",
      "=== EXPERIMENTO: Ridge ===\n",
      "✓ RMSE: $0.89\n",
      "✓ MAE:  $0.46\n",
      "✓ R²:   0.7385\n",
      "\n",
      "=== EXPERIMENTO: Lasso ===\n",
      "✓ RMSE: $0.92\n",
      "✓ MAE:  $0.50\n",
      "✓ R²:   0.7209\n",
      "\n",
      "=== EXPERIMENTO: ElasticNet ===\n",
      "✓ RMSE: $0.91\n",
      "✓ MAE:  $0.48\n",
      "✓ R²:   0.7312\n",
      "\n",
      "============================================================\n",
      "✓ 3 MODELOS REGISTRADOS EN MLFLOW\n",
      "✓ Accede a MLflow UI: http://localhost:5000\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"REGISTRANDO MODELOS CON DIFERENTE REGULARIZACIÓN\")\n",
    "\n",
    "# Lista de configuraciones\n",
    "experiments = [\n",
    "    {\"name\": \"ridge_l2_regression\", \"reg\": 0.1, \"elastic\": 0.0, \"type\": \"Ridge\"},\n",
    "    {\"name\": \"lasso_l1_regression\", \"reg\": 0.1, \"elastic\": 1.0, \"type\": \"Lasso\"},\n",
    "    {\"name\": \"elasticnet_l1_l2\", \"reg\": 0.1, \"elastic\": 0.5, \"type\": \"ElasticNet\"},\n",
    "]\n",
    "\n",
    "# Evaluadores\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_mae = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "for exp in experiments:\n",
    "\n",
    "    print(f\"\\n=== EXPERIMENTO: {exp['type']} ===\")\n",
    "\n",
    "    with mlflow.start_run(run_name=exp[\"name\"]):\n",
    "\n",
    "        # -----------------------------\n",
    "        # Log de parámetros\n",
    "        # -----------------------------\n",
    "        mlflow.log_param(\"regParam\", exp[\"reg\"])\n",
    "        mlflow.log_param(\"elasticNetParam\", exp[\"elastic\"])\n",
    "        mlflow.log_param(\"maxIter\", 100)\n",
    "        mlflow.log_param(\"model_type\", exp[\"type\"])\n",
    "\n",
    "        # -----------------------------\n",
    "        # Entrenar modelo\n",
    "        # -----------------------------\n",
    "        lr = LinearRegression(\n",
    "            featuresCol=\"features\",\n",
    "            labelCol=\"label\",\n",
    "            regParam=exp[\"reg\"],\n",
    "            elasticNetParam=exp[\"elastic\"],\n",
    "            maxIter=100\n",
    "        )\n",
    "\n",
    "        model = lr.fit(train)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Predicciones\n",
    "        # -----------------------------\n",
    "        predictions = model.transform(test)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Métricas\n",
    "        # -----------------------------\n",
    "        rmse = evaluator_rmse.evaluate(predictions)\n",
    "        mae = evaluator_mae.evaluate(predictions)\n",
    "        r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "        # -----------------------------\n",
    "        # Guardar modelo\n",
    "        # -----------------------------\n",
    "        mlflow.spark.log_model(model, \"model\")\n",
    "\n",
    "        print(f\"✓ RMSE: ${rmse:,.2f}\")\n",
    "        print(f\"✓ MAE:  ${mae:,.2f}\")\n",
    "        print(f\"✓ R²:   {r2:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ 3 MODELOS REGISTRADOS EN MLFLOW\")\n",
    "print(\"✓ Accede a MLflow UI: http://localhost:5000\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4943709c-e8d7-414a-ac88-560c6dded73a",
   "metadata": {},
   "source": [
    "Registrar múltiples métricas permite evaluar el modelo desde diferentes perspectivas. RMSE penaliza fuertemente errores grandes, MAE mide el error promedio absoluto sin amplificar outliers y R² indica qué proporción de la varianza es explicada por el modelo. Un modelo puede tener buen RMSE pero bajo R², o viceversa. Registrar varias métricas permite tomar decisiones más informadas y comparar modelos con mayor profundidad.\n",
    "\n",
    "### **Explorar y comparar runs en MLflow UI**\n",
    "\n",
    "**¿Qué modelo tiene el menor RMSE?**  \n",
    "El modelo Ridge (L2) presenta el menor RMSE dentro de los experimentos evaluados, aunque la diferencia frente a Lasso, ElasticNet y el modelo baseline es mínima y no representa una mejora significativa en términos prácticos.\n",
    "\n",
    "**¿Hay correlación entre regularización y rendimiento?**  \n",
    "No se observa una correlación clara entre el nivel o tipo de regularización y el rendimiento del modelo. Los valores de RMSE, MAE y R² son prácticamente iguales en los cuatro modelos, lo que indica que la regularización aplicada (regParam=0.1) no genera un impacto relevante en la capacidad predictiva bajo este conjunto de datos.\n",
    "\n",
    "**¿Cómo podrías compartir estos resultados con tu equipo?**  \n",
    "Los resultados pueden compartirse mediante la interfaz de MLflow UI, utilizando la opción de comparación de runs o el botón “Share” del experimento. También es posible exportar métricas, descargar artefactos registrados (modelos y reportes) o integrar MLflow con un repositorio compartido para que el equipo pueda reproducir y auditar los experimentos.\n",
    "\n",
    "### **Agregar artefactos personalizados (reportes, graficos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c14c0ed2-75c9-483b-83c6-e9aaf23fd417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===  Modelo con Artefactos ===\n",
      "✓ RMSE: $0.89\n",
      "✓ Reporte y gráfico guardados en MLflow\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "\n",
    "print(\"\\n===  Modelo con Artefactos ===\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"model_with_artifacts\"):\n",
    "\n",
    "    # Usamos los mejores hiperparámetros encontrados\n",
    "    reg_param = 0.1\n",
    "    elastic_param = 0.0  # Ridge\n",
    "    max_iter = 100\n",
    "\n",
    "    mlflow.log_param(\"regParam\", reg_param)\n",
    "    mlflow.log_param(\"elasticNetParam\", elastic_param)\n",
    "    mlflow.log_param(\"maxIter\", max_iter)\n",
    "    mlflow.log_param(\"model_type\", \"Ridge\")\n",
    "\n",
    "    # Entrenar modelo\n",
    "    lr = LinearRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        regParam=reg_param,\n",
    "        elasticNetParam=elastic_param,\n",
    "        maxIter=max_iter\n",
    "    )\n",
    "\n",
    "    model = lr.fit(train)\n",
    "    predictions = model.transform(test)\n",
    "\n",
    "    # Evaluar métricas\n",
    "    rmse = evaluator_rmse.evaluate(predictions)\n",
    "    mae = evaluator_mae.evaluate(predictions)\n",
    "    r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"mae\", mae)\n",
    "    mlflow.log_metric(\"r2\", r2)\n",
    "\n",
    "    # ==============================\n",
    "    # 1️⃣ REPORTE EN TEXTO\n",
    "    # ==============================\n",
    "\n",
    "    report = f\"\"\"\n",
    "    REPORTE DE MODELO\n",
    "    ==================\n",
    "    Modelo: Ridge Regression\n",
    "    regParam: {reg_param}\n",
    "    elasticNetParam: {elastic_param}\n",
    "    maxIter: {max_iter}\n",
    "\n",
    "    MÉTRICAS:\n",
    "    RMSE: ${rmse:,.2f}\n",
    "    MAE: ${mae:,.2f}\n",
    "    R²: {r2:.4f}\n",
    "    \"\"\"\n",
    "\n",
    "    mlflow.log_text(report, \"model_report.txt\")\n",
    "\n",
    "    # ==============================\n",
    "    # 2️⃣ GRÁFICO REAL VS PREDICHO\n",
    "    # ==============================\n",
    "\n",
    "    # Convertir pequeña muestra a pandas\n",
    "    sample_pd = predictions.select(\"label\", \"prediction\").limit(1000).toPandas()\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(sample_pd[\"label\"], sample_pd[\"prediction\"], alpha=0.5)\n",
    "    plt.xlabel(\"Valor Real\")\n",
    "    plt.ylabel(\"Valor Predicho\")\n",
    "    plt.title(\"Predicciones vs Valores Reales\")\n",
    "\n",
    "    # Línea ideal\n",
    "    min_val = sample_pd[\"label\"].min()\n",
    "    max_val = sample_pd[\"label\"].max()\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "\n",
    "    temp_plot_path = tempfile.mktemp(suffix=\".png\")\n",
    "    plt.savefig(temp_plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_artifact(temp_plot_path)\n",
    "\n",
    "    # ==============================\n",
    "    # 3️⃣ Guardar modelo\n",
    "    # ==============================\n",
    "\n",
    "    mlflow.spark.log_model(model, \"model\")\n",
    "\n",
    "    print(f\"✓ RMSE: ${rmse:,.2f}\")\n",
    "    print(\"✓ Reporte y gráfico guardados en MLflow\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4878a8-526f-41c0-b2f4-f69f8970d9d0",
   "metadata": {},
   "source": [
    "**Preguntas de Reflexión**\n",
    "\n",
    "**1. ¿Qué ventajas tiene MLflow sobre guardar métricas en archivos CSV?**  \n",
    "MLflow centraliza parámetros, métricas, modelos y artefactos en un mismo sistema versionado, permitiendo comparar experimentos fácilmente. Un CSV no mantiene trazabilidad, control de versiones ni almacenamiento de modelos asociados.\n",
    "\n",
    "**2. ¿Cómo implementarías MLflow en un proyecto de equipo?**  \n",
    "Se configuraría un tracking server centralizado accesible por todos los miembros. Cada experimento se registraría automáticamente desde los notebooks o pipelines, permitiendo auditoría, comparación y control de versiones colaborativo.\n",
    "\n",
    "**3. ¿Qué artefactos adicionales guardarías además del modelo?**  \n",
    "Gráficos de métricas, matrices de error, reportes de validación, pipelines completos de preprocesamiento, logs de entrenamiento, configuración del entorno y snapshots del dataset utilizado.\n",
    "\n",
    "**4. ¿Cómo automatizarías el registro de experimentos?**  \n",
    "Integrando MLflow dentro de pipelines CI/CD o jobs programados, donde cada entrenamiento registre automáticamente parámetros, métricas y artefactos sin intervención manual.\n",
    "\n",
    "\n",
    "## **Notebook_11**\n",
    "\n",
    "### **Configurar MLflow y MlflowClient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bf89d39-1964-4c20-bd74-64e1b7e46690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'secop_prediccion_contratos' eliminado del Registry.\n"
     ]
    }
   ],
   "source": [
    "# Elimina el modelo en el dado caso de que se cargue de mas \n",
    "\n",
    "# from mlflow.tracking import MlflowClient\n",
    "\n",
    "# client = MlflowClient()\n",
    "# model_name = \"secop_prediccion_contratos\"\n",
    "\n",
    "# Elimina el modelo completo del Model Registry\n",
    "# client.delete_registered_model(model_name)\n",
    "# print(f\"Modelo '{model_name}' eliminado del Registry.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1d15ed1-01ee-4978-83e8-6a1ea2c5b068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow URI: http://mlflow:5000\n",
      "Modelo en Registry: secop_prediccion_contratos\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Cliente del Model Registry\n",
    "client = MlflowClient()\n",
    "\n",
    "# Nombre del modelo en el Registry\n",
    "model_name = \"secop_prediccion_contratos\"\n",
    "\n",
    "print(f\"MLflow URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Modelo en Registry: {model_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aab5d9-7bf7-4572-8f21-72278f852429",
   "metadata": {},
   "source": [
    "### **Entrenar y registrar modelo v1 (baseline)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c52f6b7f-a345-4d92-817b-6d3b3f0ffe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/02/14 06:55:19 WARN Instrumentation: [c05bf145] regParam is zero, which might cause numerical instability and overfitting.\n",
      "Successfully registered model 'secop_prediccion_contratos'.\n",
      "2026/02/14 06:55:30 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: secop_prediccion_contratos, version 1\n",
      "Created version '1' of model 'secop_prediccion_contratos'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo v1 registrado | RMSE: $0.89\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"SECOP_Model_Registry\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"model_v1_baseline\") as run:\n",
    "\n",
    "    # Modelo SIN regularización\n",
    "    lr = LinearRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        regParam=0.0,\n",
    "        elasticNetParam=0.0,\n",
    "        maxIter=100\n",
    "    )\n",
    "\n",
    "    model_v1 = lr.fit(train)\n",
    "\n",
    "    predictions_v1 = model_v1.transform(test)\n",
    "    rmse_v1 = evaluator_rmse.evaluate(predictions_v1)\n",
    "\n",
    "    # Log\n",
    "    mlflow.log_param(\"version\", \"1.0\")\n",
    "    mlflow.log_param(\"model_type\", \"baseline\")\n",
    "    mlflow.log_param(\"regParam\", 0.0)\n",
    "    mlflow.log_metric(\"rmse\", rmse_v1)\n",
    "\n",
    "    # Registro en el Model Registry\n",
    "    mlflow.spark.log_model(\n",
    "        spark_model=model_v1,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "\n",
    "    run_id_v1 = run.info.run_id\n",
    "    print(f\"Modelo v1 registrado | RMSE: ${rmse_v1:,.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4bf01b-d3fd-4b32-99f8-0fcf6bda9472",
   "metadata": {},
   "source": [
    "### **Entrenar y registrar modelo v2 (mejorado)**\n",
    "\n",
    "¿Por qué versionar modelos en lugar de sobrescribir?\n",
    "\n",
    "Porque permite trazabilidad, rollback seguro, auditoría y comparación histórica entre modelos. En producción nunca se debe perder el historial de versiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f359c9d-2257-4aaf-b70d-e22cd5e49d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'secop_prediccion_contratos' already exists. Creating a new version of this model...\n",
      "2026/02/14 06:55:42 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: secop_prediccion_contratos, version 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo v2 registrado | RMSE: $0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'secop_prediccion_contratos'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"model_v2_regularized\") as run:\n",
    "\n",
    "    lr = LinearRegression(\n",
    "        featuresCol=\"features\",\n",
    "        labelCol=\"label\",\n",
    "        regParam=0.1,\n",
    "        elasticNetParam=0.5,\n",
    "        maxIter=100\n",
    "    )\n",
    "\n",
    "    model_v2 = lr.fit(train)\n",
    "\n",
    "    predictions_v2 = model_v2.transform(test)\n",
    "    rmse_v2 = evaluator_rmse.evaluate(predictions_v2)\n",
    "\n",
    "    mlflow.log_param(\"version\", \"2.0\")\n",
    "    mlflow.log_param(\"model_type\", \"regularized\")\n",
    "    mlflow.log_param(\"regParam\", 0.1)\n",
    "    mlflow.log_param(\"elasticNetParam\", 0.5)\n",
    "    mlflow.log_metric(\"rmse\", rmse_v2)\n",
    "\n",
    "    mlflow.spark.log_model(\n",
    "        spark_model=model_v2,\n",
    "        artifact_path=\"model\",\n",
    "        registered_model_name=model_name\n",
    "    )\n",
    "\n",
    "    print(f\"Modelo v2 registrado | RMSE: ${rmse_v2:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cef66a6-281a-4e70-8eb2-19925225a6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparación:\n",
      "v1 RMSE: $0.89\n",
      "v2 RMSE: $0.91\n",
      "Mejor modelo: v1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComparación:\")\n",
    "print(f\"v1 RMSE: ${rmse_v1:,.2f}\")\n",
    "print(f\"v2 RMSE: ${rmse_v2:,.2f}\")\n",
    "print(f\"Mejor modelo: {'v2' if rmse_v2 < rmse_v1 else 'v1'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c222b86-d879-4a78-8a2b-4892a0f8b127",
   "metadata": {},
   "source": [
    "### **Gestionar stages: None → Staging → Production → Archived**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e57bcc23-1afa-4d4e-b481-0077f9ea843d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GESTIÓN DE VERSIONES EN MODEL REGISTRY\n",
      "============================================================\n",
      "\n",
      "Versiones actuales del modelo 'secop_prediccion_contratos':\n",
      "  - Versión 2 | Stage: None\n",
      "  - Versión 1 | Stage: None\n",
      "\n",
      "Comparando métricas:\n",
      "  v1 RMSE: $0.89\n",
      "  v2 RMSE: $0.91\n",
      "\n",
      "Mejor versión: v1\n",
      "v1 -> Staging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/2731657312.py:22: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.9.2/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n",
      "/tmp/ipykernel_19/2731657312.py:31: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.9.2/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n",
      "/tmp/ipykernel_19/2731657312.py:40: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.9.2/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 -> Production\n",
      "v2 -> Archived\n",
      "\n",
      "Estado final de versiones:\n",
      "  - Versión 2 | Stage: Archived\n",
      "  - Versión 1 | Stage: Production\n"
     ]
    }
   ],
   "source": [
    "print(\"GESTIÓN DE VERSIONES EN MODEL REGISTRY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Listar versiones registradas\n",
    "model_versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "\n",
    "print(f\"\\nVersiones actuales del modelo '{model_name}':\")\n",
    "for mv in model_versions:\n",
    "    print(f\"  - Versión {mv.version} | Stage: {mv.current_stage}\")\n",
    "\n",
    "# Determinar mejor versión según RMSE\n",
    "print(\"\\nComparando métricas:\")\n",
    "print(f\"  v1 RMSE: ${rmse_v1:,.2f}\")\n",
    "print(f\"  v2 RMSE: ${rmse_v2:,.2f}\")\n",
    "\n",
    "best_version = 2 if rmse_v2 < rmse_v1 else 1\n",
    "worst_version = 1 if best_version == 2 else 2\n",
    "\n",
    "print(f\"\\nMejor versión: v{best_version}\")\n",
    "\n",
    "# Promover mejor versión a Staging\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=best_version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "\n",
    "print(f\"v{best_version} -> Staging\")\n",
    "\n",
    "# Simular validación (aquí ya se sabe cuál es mejor)\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=best_version,\n",
    "    stage=\"Production\"\n",
    ")\n",
    "\n",
    "print(f\"v{best_version} -> Production\")\n",
    "\n",
    "# Archivar versión anterior\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=worst_version,\n",
    "    stage=\"Archived\"\n",
    ")\n",
    "\n",
    "print(f\"v{worst_version} -> Archived\")\n",
    "\n",
    "# Verificar estado final\n",
    "print(\"\\nEstado final de versiones:\")\n",
    "model_versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "for mv in model_versions:\n",
    "    print(f\"  - Versión {mv.version} | Stage: {mv.current_stage}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e5d38-ec5d-499b-9eec-e8a671d2f182",
   "metadata": {},
   "source": [
    "### **Agregar metadata y descripcion al modelo**\n",
    "\n",
    "**¿Qué información mínima debería tener cada versión?**\r\n",
    "\r\n",
    "Cada versión de modelo debe incluir como mínimo:\r\n",
    "- Métrica principal de validación (RMSE u otra relevante)\r\n",
    "- Fecha de entrenamiento\r\n",
    "- Dataset utilizado\r\n",
    "- Tipo de modelo y configuración principal\r\n",
    "- Responsable o autor\r\n",
    "- Estado del modelo (Staging o Production)\r\n",
    "\r\n",
    "Esto garantiza trazabilidad, auditoría y reproducibilidad en entornos productivos.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d622f6a5-de69-48f7-9a9c-bcf572b8c026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Buscando versión en Production...\n",
      "Versión en Production: 1\n"
     ]
    }
   ],
   "source": [
    "# Identificar versión en Production\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "print(\"\\nBuscando versión en Production...\")\n",
    "\n",
    "production_version = None\n",
    "\n",
    "for mv in client.search_model_versions(f\"name='{model_name}'\"):\n",
    "    if mv.current_stage == \"Production\":\n",
    "        production_version = mv.version\n",
    "        break\n",
    "\n",
    "print(f\"Versión en Production: {production_version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a186811f-e182-40dc-85bc-91574e58df99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Metadata agregada a versión 1\n"
     ]
    }
   ],
   "source": [
    "# Agregar Descripción Profesional\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=production_version,\n",
    "    description=f\"\"\"\n",
    "Modelo oficial en producción para predicción de valor de contratos SECOP.\n",
    "\n",
    "• Versión: {production_version}\n",
    "• RMSE validación: ${rmse_v1:,.2f}\n",
    "• Dataset: secop_ml_ready.parquet\n",
    "• Features: PCA\n",
    "• Autor: Diego_Gomez_and_Victor_Diaz\n",
    "• Fecha: 2026-02-13\n",
    "\n",
    "Modelo seleccionado tras comparación entre baseline y modelo regularizado.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Metadata agregada a versión {production_version}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f1123c1-501c-4f8f-8c92-c7319168b193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Tags agregados correctamente\n"
     ]
    }
   ],
   "source": [
    "# Agregar Tags \n",
    "client.set_model_version_tag(\n",
    "    name=model_name,\n",
    "    version=production_version,\n",
    "    key=\"status\",\n",
    "    value=\"validated\"\n",
    ")\n",
    "\n",
    "client.set_model_version_tag(\n",
    "    name=model_name,\n",
    "    version=production_version,\n",
    "    key=\"area\",\n",
    "    value=\"finanzas_publicas\"\n",
    ")\n",
    "\n",
    "client.set_model_version_tag(\n",
    "    name=model_name,\n",
    "    version=production_version,\n",
    "    key=\"framework\",\n",
    "    value=\"SparkML\"\n",
    ")\n",
    "\n",
    "print(\"✓ Tags agregados correctamente\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c094427f-09d1-4ccf-b593-2015ee00801c",
   "metadata": {},
   "source": [
    "### **Cargar modelo desde Registry para prediccion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee049fcc-8815-4f73-becc-e53d5344594d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/mlflow/store/artifact/utils/models.py:32: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.9.2/model-registry.html#migrating-from-stages\n",
      "  latest = client.get_latest_versions(name, None if stage is None else [stage])\n",
      "2026/02/14 06:58:26 INFO mlflow.spark: 'models:/secop_prediccion_contratos/Production' resolved as 'file:///opt/mlflow/mlruns/183258816077697738/afaf868be7984fc39c07b46e91d23864/artifacts/model'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARGANDO MODELO DESDE PRODUCTION\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/14 06:58:26 INFO mlflow.spark: URI 'models:/secop_prediccion_contratos/Production/sparkml' does not point to the current DFS.\n",
      "2026/02/14 06:58:26 INFO mlflow.spark: File 'models:/secop_prediccion_contratos/Production/sparkml' not found on DFS. Will attempt to upload the file.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado desde: models:/secop_prediccion_contratos/Production\n",
      "Tipo de objeto: <class 'pyspark.ml.pipeline.PipelineModel'>\n",
      "\n",
      "RMSE verificación: $0.89\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"CARGANDO MODELO DESDE PRODUCTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Definir URI usando nombre y stage (NO ruta de archivo)\n",
    "model_uri = f\"models:/{model_name}/Production\"\n",
    "\n",
    "# Cargar modelo desde Registry\n",
    "loaded_model = mlflow.spark.load_model(model_uri)\n",
    "\n",
    "print(f\"Modelo cargado desde: {model_uri}\")\n",
    "print(f\"Tipo de objeto: {type(loaded_model)}\")\n",
    "\n",
    "# Verificar que funciona haciendo predicciones\n",
    "test_predictions = loaded_model.transform(test)\n",
    "\n",
    "# Evaluar nuevamente\n",
    "test_rmse = evaluator_rmse.evaluate(test_predictions)\n",
    "\n",
    "print(f\"\\nRMSE verificación: ${test_rmse:,.2f}\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a08c0-b5e5-4bc8-ad41-f0d4ea900f8b",
   "metadata": {},
   "source": [
    "1. ¿Cómo harías rollback si el modelo en Production falla?\n",
    "\n",
    "Si el modelo en Production presenta fallos, realizaría rollback promoviendo la versión anterior desde \"Archived\" o \"Staging\" nuevamente a \"Production\" utilizando transition_model_version_stage(). Esto permite revertir el modelo activo sin modificar el código de producción, ya que el sistema siempre carga el modelo por nombre y stage.\n",
    "\n",
    "2. ¿Qué criterios usarías para promover un modelo de Staging a Production?\n",
    "\n",
    "Promovería un modelo a Production únicamente si:\n",
    "\n",
    "  - Presenta mejor RMSE/MAE/R² que la versión actual.\n",
    "  - Supera validaciones técnicas y de negocio.\n",
    "  - Es estable en pruebas controladas.\n",
    "  - No introduce sesgos o comportamientos inesperados.\n",
    "  - Ha sido revisado y aprobado por el equipo responsable.\n",
    "\n",
    "3. ¿Cómo implementarías A/B testing con el Model Registry?\n",
    "\n",
    "Implementaría A/B testing desplegando dos versiones diferentes del modelo (por ejemplo, Production y Staging) y enviando un porcentaje del tráfico a cada uno. Posteriormente compararía métricas en producción (errores reales, impacto financiero, latencia) para determinar cuál modelo ofrece mejor rendimiento antes de hacer la promoción definitiva.\n",
    "\n",
    "4. ¿Quién debería tener permisos para promover modelos a Production?\n",
    "\n",
    "Solo deberían tener permisos para promover modelos a Production los roles responsables de MLOps o Data Science Lead, ya que este proceso impacta directamente el entorno productivo. Esto evita errores humanos y mantiene control y trazabilidad sobre cambios críticos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d204cfe-7873-4156-a04b-361cc52613dc",
   "metadata": {},
   "source": [
    "## **Notebook_12**\n",
    "\n",
    "1. ¿Por qué cargar desde el Registry en lugar de una ruta de archivo? ¿Qué ventajas tiene para un sistema de producción?\n",
    "\n",
    "  - Permite cambiar la versión en Production sin modificar código.\n",
    "  - Facilita rollback inmediato.\n",
    "  - Centraliza control y gobernanza.\n",
    "  - Garantiza trazabilidad y versionamiento.\n",
    "\n",
    "2. ¿Qué pasaría si no hay modelo en Production?\n",
    "\n",
    "El sistema lanzaría un error porque no existe una versión promovida a ese stage.\n",
    "\n",
    "3. ¿Cómo manejar ese error?\n",
    "\n",
    "  - Capturar la excepción (como hicimos arriba).\n",
    "  - Enviar alerta.\n",
    "  - Cargar versión anterior estable.\n",
    "  - Detener el pipeline si es crítico.\n",
    "\n",
    "### **Cargar modelo en Production desde MLflow Registry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad479588-67ce-4490-a1c0-3197eb47d4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/14 06:58:52 INFO mlflow.spark: 'models:/secop_prediccion_contratos/Production' resolved as 'file:///opt/mlflow/mlruns/183258816077697738/afaf868be7984fc39c07b46e91d23864/artifacts/model'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CARGANDO MODELO DESDE REGISTRY\n",
      "============================================================\n",
      "URI: models:/secop_prediccion_contratos/Production\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/02/14 06:58:52 INFO mlflow.spark: URI 'models:/secop_prediccion_contratos/Production/sparkml' does not point to the current DFS.\n",
      "2026/02/14 06:58:53 INFO mlflow.spark: File 'models:/secop_prediccion_contratos/Production/sparkml' not found on DFS. Will attempt to upload the file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modelo cargado correctamente\n",
      "Tipo: <class 'pyspark.ml.pipeline.PipelineModel'>\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://mlflow:5000\")\n",
    "# nombre del modelo registrado\n",
    "model_name = \"secop_prediccion_contratos\"\n",
    "model_uri = f\"models:/{model_name}/Production\"\n",
    "\n",
    "print(\"CARGANDO MODELO DESDE REGISTRY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"URI: {model_uri}\")\n",
    "\n",
    "try:\n",
    "    production_model = mlflow.spark.load_model(model_uri)\n",
    "    print(\"✓ Modelo cargado correctamente\")\n",
    "    print(f\"Tipo: {type(production_model)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"No existe modelo en Production\")\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5483cfa7-55c4-4d83-aa17-f1aecd016744",
   "metadata": {},
   "source": [
    "### **Preparar datos nuevos para prediccion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "623b7caa-a7c6-4b00-af9f-483ce5b7ec9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros para predicción: 100,000\n",
      "Columnas disponibles:\n",
      "['features']\n"
     ]
    }
   ],
   "source": [
    "df_new = spark.read.parquet(\"/opt/spark-data/raw/secop_ml_ready.parquet\")\n",
    "df_new = df_new.withColumnRenamed(\"features_pca\", \"features\")\n",
    "\n",
    "# Simular que no tenemos label en producción\n",
    "df_new_no_label = df_new.drop(\"valor_del_contrato_log\")\n",
    "\n",
    "print(f\"Registros para predicción: {df_new_no_label.count():,}\")\n",
    "print(\"Columnas disponibles:\")\n",
    "print(df_new_no_label.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b13b31-61ca-4f1c-8e3f-fdedab58fe61",
   "metadata": {},
   "source": [
    "### **Generar predicciones batch con timestamp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a2e515d-e238-49e3-9c5c-3e3b39439a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+--------------------------+\n",
      "|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |prediction        |prediction_timestamp      |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+--------------------------+\n",
      "|[-2.8319118047154017,-0.8950380351127657,-5.537292739494909,2.6421944386534406,-0.20962974469589943,0.34566131648302745,-1.1389723353489194,-0.3654307317938236,-2.393079494105536,1.0680422215402143,-0.7455597998453163,-1.1585728573529492,-0.9479810383921783,-1.9726567317257455,0.014326698663671592,1.1812924284317567,-0.3309570779596676,0.050879920144909115,-0.5205180999171637,0.05234341313828478,0.06816712121055542,0.042288825732354665,-0.15762149020389846,0.3573928409989558,-0.08879569729935502,0.10180157011928842,0.21615537756316855,0.16344309356274953,-0.18215943601138265,-0.43867362031316076]         |16.89718593937235 |2026-02-14 06:59:41.062323|\n",
      "|[-1.8585618244350957,-0.9185266237745408,-5.732466888761126,2.184236483550238,-3.2337603943584075,-1.2650831582537674,0.660311005253442,0.27029221410497456,-0.06347250880772556,-0.07444838734951348,-0.7315418257971631,0.37870829635610637,0.1242593931493749,-0.716889729599429,-0.46911347816042454,-0.7137340317285435,-0.8372084579277429,-0.9324752176857203,1.252558604879691,1.2985678999257961,0.29442362675589856,-0.3637784633903905,-0.24500879129704864,-0.034963342618687304,-0.07733596214082432,0.8086264017104842,0.5445023985428077,-0.7351749144931864,-0.2593322343416039,0.3444191474775334]                 |16.808246795987635|2026-02-14 06:59:41.062323|\n",
      "|[1.6843114421646943,0.8874984522478535,-6.399157200313428,2.4003079718633926,-3.2129061185403094,0.7286312628006255,1.600208399529247,-0.3854225500511371,-0.1288324470881906,-0.6965795070876042,-3.1316784064037844,0.7157703461455642,-0.08384147157951999,-0.33653410662331273,-0.8092863191326805,-0.24343383930854245,-0.5312801123431133,-0.10729949273196535,-0.15188722506978936,-0.6094278698661216,-0.5810014504411429,0.057898936288733174,-0.014299453979051038,-0.12806376228768857,0.14182085705431444,-0.10057885463697797,0.0880719946470637,0.4086870751803024,0.05107125222663495,-0.5320359812267234]           |17.566962797649925|2026-02-14 06:59:41.062323|\n",
      "|[-2.7706526339944193,-1.1425102671137521,-6.384442375721324,2.6655866095964185,0.20267378591386032,0.65920206951792,0.836348491281812,0.26441561891154447,-0.11451397687245876,-1.3993713988492396,0.9048305927851497,0.15261387043883973,-0.10545525722020917,-0.4805635752727955,0.7676320969020043,1.0195721507938578,0.37733050013057107,-1.218865806837839,-0.15810998062909898,0.7423833441888387,-0.9635922056262681,0.5261729401848756,0.8373417584909317,-0.9419384618768984,-0.07890785018328288,0.7556072898294776,-0.638169190430896,0.8249163016973567,-7.439969181017367,2.9832161523782665]                          |17.926165945500887|2026-02-14 06:59:41.062323|\n",
      "|[-2.75586059717663,-0.8161996924565608,-5.196534492051057,2.1861686392613366,-0.8828039445151257,1.6657648366868303,0.5154925993253267,3.2043968580508477,-1.3451901824941481,-0.1655911715020676,0.26264625035651906,0.881079023511232,0.39831139702707496,-0.5461207070968911,-0.3149753880815788,0.9369266899546864,0.13025715415829936,-0.8292732558349509,0.029842970921948833,-0.2667876747014326,-0.2966029601272065,-0.1232828163131277,0.12834948367859855,-0.05746736058045805,0.07222099090862882,0.2157179644854318,0.14975092139645035,0.2660673731745006,-0.07788056838000842,-0.5820953579907762]                    |16.854203145347924|2026-02-14 06:59:41.062323|\n",
      "|[-3.4732503533498,-1.1571783827583841,-6.739929846786673,0.4901252562484732,-0.8676617674446035,0.26264759918149044,-0.21090928501271516,0.5962843349863918,-0.15387464921461003,0.055983493430168924,-0.05544895623412216,0.14092370255434258,-4.071777626786961E-4,-0.19672633283357774,-0.024018613738025597,0.2042701020826645,-0.15342696062517894,-0.22978340852206616,-0.14931294341980406,-0.04573546825215119,-0.2860111266841105,0.13180358216143717,0.052939216400114154,0.023646411176337506,0.03243962935663934,0.06937553328797542,0.05768050448541886,0.2055538822286029,-0.08043546088356852,-0.3067948205742688]   |17.856265354037355|2026-02-14 06:59:41.062323|\n",
      "|[-3.4685767977443684,-1.157383829686986,-6.692086278597231,0.4786447162301723,-0.8641494078422218,0.25959790705736235,-0.21043418214683524,0.5920761420821653,-0.1528074459695758,0.05556216739769085,-0.055066795166302196,0.1398511018297292,-3.2572248047058397E-4,-0.19574511362884808,-0.024161071012726857,0.20243191692249515,-0.1513714936439474,-0.22862772407739754,-0.1480598216188273,-0.04544789792422241,-0.283455824104875,0.13058464438176007,0.052463593686291964,0.023429412489413867,0.032037776562571896,0.069080295312769,0.05747380906560145,0.20346747331469947,-0.07974887154292336,-0.3044851287494974]    |17.79089998257555 |2026-02-14 06:59:41.062323|\n",
      "|[-0.7392094154650579,-2.737126035642266,-5.513768683244567,2.3277629899009447,0.07657305250817265,0.7150895288254514,0.6747316473893675,0.602530145770133,0.20389481469997608,-0.8382638097879089,0.39256779187085916,-0.7824371874846646,-0.3889297924316705,0.4908606247977256,1.2856198666858567,0.3036273092473841,-0.6488740565954342,0.5806183848412316,-0.5501733400706694,3.034664604107287,-1.2738162490623193,1.1012785248157084,4.087140158845307,2.0063384889453957,-0.025500623654188988,-0.9715946332227668,2.5183089289110256,-2.1806203498738075,1.371251023761907,-1.2801748157786506]                             |16.47530662404513 |2026-02-14 06:59:41.062323|\n",
      "|[-3.430808841161577,-1.159044088242697,-6.3054526405926845,0.38586812950159505,-0.8357653131260437,0.23495272264978184,-0.20659477893313294,0.5580688764546603,-0.14418315876164772,0.05215734574897932,-0.05197847358941071,0.13118319648785526,3.3253427768150864E-4,-0.18781568099743612,-0.025312297320929298,0.18757716752361836,-0.13476084550823517,-0.2192884022388125,-0.1379330886198168,-0.04312398341958064,-0.2628059024999426,0.12073415943482536,0.04861998947528224,0.02167580181733167,0.028790322127372158,0.06669441698573526,0.055803461197598554,0.18660677710672705,-0.07420040296847114,-0.28582003777332327]|17.26266907664212 |2026-02-14 06:59:41.062323|\n",
      "|[-0.6874545805097523,-2.0716002680984666,-5.414498596549502,2.1610514720300835,-0.38110259202903696,2.4594212037905185,-1.6299935008958584,0.0673822450731056,2.4386102801111877,0.260257497091156,0.4625776600271869,0.23103953092811783,-0.34056497167032956,-1.4302081004945368,0.11287728450968544,0.3939716695247536,-0.7664760154648927,-0.9627412260391102,0.847967173843655,0.6172085701081523,0.7939458046514155,-0.12350819149958057,0.16775206317969704,-0.36135557712902544,0.20227934948984577,0.13785466027204257,-0.21790711762841097,-0.2008125440089156,0.37441999772198026,0.2823057050457396]                    |16.30718137262935 |2026-02-14 06:59:41.062323|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+--------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "predictions_batch = production_model.transform(df_new_no_label)\n",
    "\n",
    "predictions_batch = predictions_batch.withColumn(\n",
    "    \"prediction_timestamp\",\n",
    "    current_timestamp()\n",
    ")\n",
    "\n",
    "predictions_batch.select(\n",
    "    \"features\",\n",
    "    \"prediction\",\n",
    "    \"prediction_timestamp\"\n",
    ").show(10, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65dbdd9-2e2a-4140-b36c-2d80fe1dce73",
   "metadata": {},
   "source": [
    "¿Por qué agregar timestamp?\n",
    "\n",
    " - Auditoría\n",
    " - Trazabilidad\n",
    " - Comparación entre lotes\n",
    " - Monitoreo temporal\n",
    "\n",
    "### **Monitorear predicciones (estadisticas, anomalias, rangos)**\n",
    "\n",
    "¿Cómo detectar data drift?\n",
    "\n",
    "  - Comparar media y desviación vs entrenamiento\n",
    "  - Monitorear distribución por rangos\n",
    "  - Alertas si cambia > X%\n",
    "  - Validar features entrantes\n",
    "\n",
    "Si hay drift, toca tener alertas, Evaluar retraining y Revertir versión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a00ec8a9-ae6c-4056-8e9a-762c3c95d9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ESTADÍSTICAS DE PREDICCIONES ===\n",
      "Total: 100,000\n",
      "Mínimo: $0.00\n",
      "Máximo: $8,892,625,557,609.46\n",
      "Promedio: $237,343,677.25\n",
      "Std: $37,033,573,997.19\n",
      "=== DISTRIBUCIÓN POR RANGOS ===\n",
      "+-----+--------+-------+----+\n",
      "|< 10M|10M-100M|100M-1B|> 1B|\n",
      "+-----+--------+-------+----+\n",
      "| 6313|   87957|   5265| 465|\n",
      "+-----+--------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min as spark_min, max as spark_max, avg, stddev, count\n",
    "from pyspark.sql.functions import exp\n",
    "\n",
    "predictions_batch = predictions_batch.withColumn(\n",
    "    \"prediction_real\",\n",
    "    exp(col(\"prediction\"))\n",
    ")\n",
    "\n",
    "stats = predictions_batch.select(\n",
    "    spark_min(\"prediction_real\").alias(\"min_pred\"),\n",
    "    spark_max(\"prediction_real\").alias(\"max_pred\"),\n",
    "    avg(\"prediction_real\").alias(\"avg_pred\"),\n",
    "    stddev(\"prediction_real\").alias(\"std_pred\"),\n",
    "    count(\"*\").alias(\"total\")\n",
    ").collect()[0]\n",
    "\n",
    "\n",
    "print(\"=== ESTADÍSTICAS DE PREDICCIONES ===\")\n",
    "print(f\"Total: {stats['total']:,}\")\n",
    "print(f\"Mínimo: ${stats['min_pred']:,.2f}\")\n",
    "print(f\"Máximo: ${stats['max_pred']:,.2f}\")\n",
    "print(f\"Promedio: ${stats['avg_pred']:,.2f}\")\n",
    "print(f\"Std: ${stats['std_pred']:,.2f}\")\n",
    "\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "prediction_ranges = predictions_batch.select(\n",
    "    count(when(col(\"prediction_real\") < 10000000, True)).alias(\"< 10M\"),\n",
    "    count(when((col(\"prediction_real\") >= 10000000) & (col(\"prediction_real\") < 100000000), True)).alias(\"10M-100M\"),\n",
    "    count(when((col(\"prediction_real\") >= 100000000) & (col(\"prediction_real\") < 1000000000), True)).alias(\"100M-1B\"),\n",
    "    count(when(col(\"prediction_real\") >= 1000000000, True)).alias(\"> 1B\")\n",
    ")\n",
    "\n",
    "\n",
    "print(\"=== DISTRIBUCIÓN POR RANGOS ===\")\n",
    "prediction_ranges.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f22dc4-9970-46c3-bd6d-78cfc3e9c54e",
   "metadata": {},
   "source": [
    "### **Dectectar anomalias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "325f421f-9b5d-430d-8fb6-98bdf3887287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones negativas: 0\n"
     ]
    }
   ],
   "source": [
    "anomalias = predictions_batch.filter(col(\"prediction_real\") < 0).count()\n",
    "print(f\"Predicciones negativas: {anomalias}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9eb908-6cd0-4eb4-8446-2c34c7ec59be",
   "metadata": {},
   "source": [
    "### **Guardar resultados en Parquet y CSV**\n",
    "\n",
    "¿Qué formato usarías para cada caso?\n",
    " - Dashboard interno: Parquet\n",
    " - Reporte para gerencia: CSV\n",
    " - Input para otro sistema: Depende del sistema, pero normalmente, parquet si es otro sistema Big Data / Spark / Data Lake. CSV o JSON si es API o sistema transaccional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee038408-e71a-47a9-914e-3989c5e82b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet guardado en: /opt/spark-data/raw/predictions_produccion/parquet\n",
      "CSV guardado en: /opt/spark-data/raw/predictions_produccion/csv\n"
     ]
    }
   ],
   "source": [
    "predictions_output = \"/opt/spark-data/raw/predictions_produccion\"\n",
    "\n",
    "# Guardar en Parquet (formato óptimo para analytics)\n",
    "predictions_batch.write.mode(\"overwrite\") \\\n",
    "    .parquet(predictions_output + \"/parquet\")\n",
    "\n",
    "print(f\"Parquet guardado en: {predictions_output}/parquet\")\n",
    "\n",
    "# Guardar en CSV (solo columnas necesarias)\n",
    "predictions_batch.select(\n",
    "    \"prediction_real\",\n",
    "    \"prediction_timestamp\"\n",
    ").write.mode(\"overwrite\") \\\n",
    " .option(\"header\", \"true\") \\\n",
    " .csv(predictions_output + \"/csv\")\n",
    "\n",
    "print(f\"CSV guardado en: {predictions_output}/csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e4eac0-fbfc-4e29-b16e-c75e77e354c9",
   "metadata": {},
   "source": [
    "### **Disenar pipeline de produccion automatizado**\n",
    "\n",
    "1. **Frecuencia**: ¿Cada hora? ¿Cada día? ¿Bajo demanda?\n",
    "2. **Orquestador**: ¿Airflow? ¿Cron? ¿Spark Streaming?\n",
    "3. **Monitoreo**: ¿Cómo detectas si el modelo se degrada?\n",
    "4. **Reentrenamiento**: ¿Cuándo reentrenar el modelo?\n",
    "5. **Alertas**: ¿Qué condiciones disparan una alerta?\n",
    "\n",
    "**Frecuencia**: Cada día (batch nocturno). Los contratos públicos no cambian en tiempo real, por lo que una ejecución diaria es suficiente para mantener las predicciones actualizadas sin sobrecargar infraestructura.\n",
    "\n",
    "**Orquestador**: Apache Airflow. Permite programar tareas, manejar dependencias (ETL → Scoring → Monitoreo), registrar logs, manejar reintentos y enviar alertas automáticas en caso de fallo.\n",
    "\n",
    "**Monitoreo**:Detectar degradación mediante: Comparación del RMSE histórico vs actual, cambios significativos en promedio y desviación estándar de predicciones. Detección de data drift (cambio en distribución de features), incremento de outliers o valores extremos. Si las métricas se alejan del rango esperado, el modelo puede estar degradándose.\n",
    "\n",
    "**Reentrenamiento**: Se debe reentrenar cuando:\n",
    "\n",
    "  -  El RMSE empeore más de un umbral definido (ej. +10%).\n",
    "  -  Se detecte data drift significativo.\n",
    "  -  Se acumulen nuevos datos relevantes (mensual o trimestralmente).\n",
    "\n",
    "**Alertas**: Se mandaran alertas cuando:\n",
    "\n",
    "  - El pipeline falla.\n",
    "  - El RMSE supera un umbral crítico.\n",
    "  - Se detecta data drift fuerte.\n",
    "  - Aparecen predicciones fuera de rango esperado.\n",
    "  - Hay cambios anormales en la distribución diaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66534b-0831-452a-b78c-baf00a8a2f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DISEÑO DEL PIPELINE DE PRODUCCIÓN – SECOP\n",
    "# ============================================================\n",
    "\n",
    "# 1. Frecuencia:\n",
    "#    - Ejecución diaria (batch nocturno).\n",
    "#    - Hora sugerida: 02:00 AM.\n",
    "#    - Justificación:\n",
    "#        • Los contratos públicos no requieren scoring en tiempo real.\n",
    "#        • Permite consolidar datos del día anterior.\n",
    "#        • Reduce carga sobre infraestructura en horario laboral.\n",
    "\n",
    "\n",
    "# 2. Orquestador:\n",
    "#    - Apache Airflow.\n",
    "#    - DAG propuesto:\n",
    "#\n",
    "#        Task 1: Ingesta datos nuevos (Parquet / DB / S3)\n",
    "#        Task 2: Cargar modelo desde MLflow Registry (Production)\n",
    "#        Task 3: Generar predicciones batch\n",
    "#        Task 4: Aplicar exp() para volver de escala log\n",
    "#        Task 5: Calcular métricas de monitoreo\n",
    "#        Task 6: Guardar resultados (Parquet + CSV)\n",
    "#        Task 7: Validar umbrales y disparar alertas\n",
    "#\n",
    "#    - Airflow permite:\n",
    "#        • Reintentos automáticos\n",
    "#        • Logs centralizados\n",
    "#        • Control de dependencias\n",
    "#        • Alertas por email / Slack\n",
    "\n",
    "\n",
    "# 3. Monitoreo:\n",
    "#    - Métricas monitoreadas diariamente:\n",
    "#        • Promedio de predicciones\n",
    "#        • Desviación estándar\n",
    "#        • % de valores > 1B\n",
    "#        • % de valores < 10M\n",
    "#    - Comparación contra baseline histórico.\n",
    "#    - Detección de data drift:\n",
    "#        • Comparar distribución actual vs entrenamiento.\n",
    "#        • Monitorear cambios en media y varianza de features PCA.\n",
    "#\n",
    "#    - Si el RMSE en validaciones periódicas aumenta >10%,\n",
    "#      se marca posible degradación del modelo.\n",
    "\n",
    "\n",
    "# 4. Reentrenamiento:\n",
    "#    - Condiciones para reentrenar:\n",
    "#        • RMSE aumenta más de 10% respecto al baseline.\n",
    "#        • Drift estadístico significativo.\n",
    "#        • Nuevos datos acumulados (ej: mensual).\n",
    "#\n",
    "#    - Proceso:\n",
    "#        • Ejecutar notebook de entrenamiento (Notebook 10).\n",
    "#        • Registrar nueva versión en Model Registry.\n",
    "#        • Comparar contra versión en Production.\n",
    "#        • Promover solo si mejora métricas.\n",
    "#\n",
    "#    - Nunca sobrescribir modelo:\n",
    "#        • Siempre versionar.\n",
    "#        • Usar stages (None → Staging → Production).\n",
    "\n",
    "\n",
    "# 5. Alertas:\n",
    "#    - Se dispara alerta si:\n",
    "#        • Pipeline falla.\n",
    "#        • No se generan predicciones.\n",
    "#        • Predicciones negativas > 0.\n",
    "#        • Promedio cambia >20% respecto al histórico.\n",
    "#        • Máximo excede umbral crítico definido.\n",
    "#\n",
    "#    - Canales de alerta:\n",
    "#        • Email automático.\n",
    "#        • Slack.\n",
    "#        • Registro en dashboard interno.\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Resultado esperado:\n",
    "# Pipeline automatizado, versionado, monitoreado y gobernado.\n",
    "# ============================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef33558-4ff7-49aa-be6b-a3cf87f18089",
   "metadata": {},
   "source": [
    "### **Simulacion de scoring continuo por lotes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bda0df77-f6ab-4f58-826c-2149580490b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIMULACIÓN DE SCORING CONTINUO POR LOTES\n",
      "============================================================\n",
      "Lote 1: 33,060 registros | Predicción promedio: $49,762,825.50\n",
      "Lote 2: 33,198 registros | Predicción promedio: $52,075,359.08\n",
      "Lote 3: 33,742 registros | Predicción promedio: $603,414,466.94\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg, exp, col\n",
    "\n",
    "print(\"SIMULACIÓN DE SCORING CONTINUO POR LOTES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dividir en 3 lotes simulados\n",
    "batches = df_new_no_label.randomSplit([0.33, 0.33, 0.34], seed=42)\n",
    "\n",
    "for i, batch in enumerate(batches):\n",
    "    \n",
    "    # Generar predicciones en escala log\n",
    "    preds = production_model.transform(batch)\n",
    "    \n",
    "    # Convertir a escala real (porque entrenamos en log1p)\n",
    "    preds = preds.withColumn(\n",
    "        \"prediction_real\",\n",
    "        exp(col(\"prediction\"))\n",
    "    )\n",
    "    \n",
    "    # Calcular estadísticas básicas\n",
    "    avg_pred = preds.select(avg(\"prediction_real\")).collect()[0][0]\n",
    "    count_pred = preds.count()\n",
    "    \n",
    "    print(f\"Lote {i+1}: {count_pred:,} registros | \"\n",
    "          f\"Predicción promedio: ${avg_pred:,.2f}\")\n",
    "\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21c74833-0523-47e1-86b5-8ec035eff992",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
